{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2508632,"sourceType":"datasetVersion","datasetId":1519260},{"sourceId":12819293,"sourceType":"datasetVersion","datasetId":8106424}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nresume_path = []\nbase_dir = \"/kaggle/input/resume-dataset\"\n\n\nfor root , dirs ,  files in os.walk(base_dir):\n    for file in files:\n        if file.endswith((\".pdf\" , \".docx\" , \".txt\")):\n\n          resume_path.append(os.path.join(root , file))\n\n!pip install docx2txt\n!pip install pdfplumber\nimport docx2txt\nimport pdfplumber\n\ndef extract_text_from_pdf(resume_path):\n    text = \" \"\n    with pdfplumber.open(path) as pdf:\n        for page in pdf.pages:\n            text += page.extract_text() + \"\\n\"\n    return text\n\ndef clean_text(text):\n\n    text = re.sub(r'\\s+' , ' ' , text)\n\n    text = re.sub(r'[^\\x00-\\x7F]+' , ' ' , text)\n    return text.strip()\n\n\ndef preprocess_text(text):\n\n    text = text.lower()\n\n    tokens= text.split()\n    return tokens \n\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef extract_name(text):\n    doc = nlp(text)\n    for ent in doc.ents:\n        if ent.label_ == \"PERSON\":\n            return ent.text\n    first_line = text.strip().split(\"\\n\")[0]\n\n    if len(first_line.split()) <= 4:\n        return first_line\n    return None\n\ndef extract_email(text):\n    email = re.findall(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+' , text)\n    if email:\n        return email[0].lower().strip(\";,\")\n    return None\n\ndef extract_phone(text):\n    phone = re.findall(r'(\\+?\\d{1,3}[-\\s]?)?\\d{10}' , text)\n    if phone:\n        return phone[0].strip()\n    return None\n\ndef extract_education(text):\n    education_keywords = [ \"b.tech\", \"b.e\" , \"m.tech\" , \"m.e\" , \"b.sc\" , \"m.sc\" , \"mba\" , \"phd\" ,\"bachelor\" , \"master\" , \"university\" , \"college\" , \"school\"]\n\n    lines = text.lower().split(\"\\n\")\n    education = [line for line in lines if any(k in line.lower() for k in education_keywords)]\n    return education if education else None\n\n\nskills_db = [\"python\" , \"java\" , \"c++\" , \"sql\" , \"tensorflow\" , \"keras\" , \"machinelearning\" , \"deep leaning\"]\n\nimport re\ndef extract_skills(text):\n    text_lower = text.lower()\n    found = []\n    for skill in skills_db:\n        if re.search(r'\\b' + re.escape(skill) + r'\\b' , text_lower):\n            found.append(skill)\n    return list(set(found)) if found else None\n\ndef extract_experience(text):\n    lines = text.split(\"\\n\")\n    exp = [line for line in lines if \"experience\" in line.lower() or \"intern\" in line.lower()]\n    return exp\n\n\ndef parse_resume(text):\n    return {\n        \"name\" : extract_name(text) ,\n        \"education\" : extract_education(text) ,\n        \"skills\": extract_skills(text) ,\n        \"experience\" : extract_experience(text)    \n    }\n\nimport os , pandas as pd\n\nresults = []\n\nfor path in resume_path:\n\n    if path.endswith(\".pdf\"):\n        text = extract_text_from_pdf(path)\n    else:\n        continue\n\n    parsed = parse_resume(text)\n    parsed[\"filename\"] = os.path.basename(path)\n    results.append(parsed)\n\ndf = pd.DataFrame(results)\ndf.to_csv(\"parsed_resumes.csv\" , index = False)\n \n\nfor r in results:\n    if not r.get('name'):\n        r['name'] = 'Unknown'\n    if not r.get('email'):\n        r['email'] = 'Not found'\n\n\n\nimport json\nwith open(\"parsed_resumes.json\" , \"w\") as f:\n    json.dump(results , f , indent = 4)\n\n\nprint(len(results))\n\n\n\n\n\n\n\n\n\n\n \n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T03:50:10.008969Z","iopub.execute_input":"2025-08-30T03:50:10.009263Z","iopub.status.idle":"2025-08-30T04:17:08.824333Z","shell.execute_reply.started":"2025-08-30T03:50:10.009241Z","shell.execute_reply":"2025-08-30T04:17:08.823648Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: docx2txt in /usr/local/lib/python3.11/dist-packages (0.9)\nRequirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.7)\nRequirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250506)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\nRequirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.0)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (44.0.3)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n2484\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip install reportlab\nimport json\nfrom reportlab.lib.pagesizes import A4\nfrom reportlab.platypus import SimpleDocTemplate , Paragraph , Spacer , PageBreak\nfrom reportlab.lib.styles import getSampleStyleSheet\n\nstyles = getSampleStyleSheet()\ncombined_filename = \"Combined_Resumes.pdf\"\n\ndoc = SimpleDocTemplate(combined_filename , pagesize = A4)\n\nstory = []\n\nfor idx, r in enumerate(results):\n    name = r.get(\"name\" , \"Unknown\")\n    email = r.get(\"email\", \"Not found\")\n    education = r.get(\"education\", \"Not provided\")\n    experience  = r.get(\"experience\" , \"Not provided\")\n    skills = r.get(\"skills\" , \"Not provided\")\n\n    \n    if not isinstance(education , list):\n      education = [education]\n    if not isinstance(experience , list):\n      experience = [experience]\n    \n    story.append(Paragraph(f\"<b>Role:</b>{name}\" , styles['Title'])) \n    story.append(Spacer(1,12)) \n    story.append(Paragraph(f\"<b>Experience:</b>\" , styles['Heading2']))\n    for exp in experience:\n            story.append(Paragraph(f\"* {exp}\" , styles['Normal']))\n    story.append(Spacer(1,12))\n    \n    story.append(Paragraph(f\"<b>Education:</b>\" , styles['Heading2']))\n    for edu in education:\n             story.append(Paragraph(f\"* {edu}\" , styles['Normal']))\n    story.append(Spacer(1,12))\n\n    story.append(Spacer(1,24))\n    story.append(PageBreak())\n\ndoc.build(story)\nprint(f\"PDF generated: {combined_filename}\")\n\n\n\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T03:07:30.163795Z","iopub.execute_input":"2025-08-30T03:07:30.164100Z","iopub.status.idle":"2025-08-30T03:07:39.344685Z","shell.execute_reply.started":"2025-08-30T03:07:30.164077Z","shell.execute_reply":"2025-08-30T03:07:39.343906Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: reportlab in /usr/local/lib/python3.11/dist-packages (4.4.3)\nRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab) (11.2.1)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from reportlab) (3.4.2)\nPDF generated: Combined_Resumes.pdf\n","output_type":"stream"}],"execution_count":8}]}